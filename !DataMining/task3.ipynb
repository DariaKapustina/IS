{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impotring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import tree  \n",
    "from sklearn import naive_bayes\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import dummy, metrics\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(name):\n",
    "    dataset = getattr(datasets, 'load_'+name)()\n",
    "\n",
    "    dataset_frame = pd.DataFrame(dataset.data)\n",
    "    dataset_frame['target'] = dataset.target\n",
    "    target = dataset_frame['target'] \n",
    "    data = dataset_frame.drop(columns = ['target'])\n",
    "\n",
    "    print (\"Class distibution\")\n",
    "    print (target.value_counts())\n",
    "\n",
    "    print (\"Class distibution\")\n",
    "    dataset_frame.sample(10)\n",
    "    return dataset, data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSVM(train_data, test_data, train_labels, test_labels, folds, hyper_params_svc):\n",
    "    \n",
    "    f1_scorer = metrics.make_scorer(metrics.f1_score, average='weighted')\n",
    "    \n",
    "    classifier_svc = svm.SVC()\n",
    "    \n",
    "    svm_grid = ms.GridSearchCV(classifier_svc, \n",
    "                               hyper_params_svc,  # parameters to tune via cross validation\n",
    "                               refit=True,        # fit using all available data at the end, on the best found param combination\n",
    "                               scoring=f1_scorer,  \n",
    "                               cv=ms.StratifiedKFold(n_splits=folds)\n",
    "    )\n",
    "\n",
    "    svm_grid_best_model = svm_grid.fit(train_data, train_labels)\n",
    "\n",
    "    print(\"Best hyper-parameters:\")\n",
    "    print(svm_grid_best_model.best_params_)\n",
    "\n",
    "    predictions_svm = svm_grid_best_model.predict(test_data)\n",
    "\n",
    "    svm_grid_best_model_f1 = metrics.f1_score(test_labels, predictions_svm, average='weighted')\n",
    "    print (\"SVM: \")\n",
    "    print (\"f1 = {:.3f}\".format(svm_grid_best_model_f1))\n",
    "\n",
    "    print (metrics.classification_report(test_labels, predictions_svm))\n",
    "    #metrics.plot_confusion_matrix(svm_grid_best_model, test_data, test_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def getDecisionTreeClassifier(model, train_data, test_data, train_labels, test_labels):\n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted');\n",
    "    print (\"DecisionTreeClassifier: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))\n",
    "    \n",
    "def getLogisticRegression(model, train_data, test_data, train_labels, test_labels):\n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted');\n",
    "    print (\"LogisticRegression: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))\n",
    "    \n",
    "def getNaiveBayes(model, train_data, test_data, train_labels, test_labels):\n",
    "\n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted');\n",
    "    print (\"NaiveBayes: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))\n",
    "    \n",
    "def getRandomForestClassifier(model, train_data, test_data, train_labels, test_labels):\n",
    "    \n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted');\n",
    "    print (\"RandomForestClassifier: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))\n",
    "    \n",
    "def getAdaBoostClassifier(model, train_data, test_data, train_labels, test_labels):\n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted', labels=np.unique(predictions));\n",
    "    print (\"AdaBoostClassifier: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))\n",
    "\n",
    "def getVotingClassifier(train_data, test_data, train_labels, test_labels):\n",
    "    model.fit (train_data, train_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "    f1_score = metrics.f1_score(test_labels, predictions, average='weighted');\n",
    "    print (\"VotingClassifier: \")\n",
    "    print (\"f1 = {:.3f}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaseline(train_data, train_labels):\n",
    "    baseline = dummy.DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(train_data, train_labels)\n",
    "    base_predictions = baseline.predict(data)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(train_labels, base_predictions)\n",
    "    recall = metrics.recall_score(train_labels, base_predictions, average='weighted')\n",
    "    precision = metrics.precision_score(train_labels, base_predictions, average='weighted')\n",
    "    f1 = metrics.f1_score(train_labels, base_predictions, average='weighted')\n",
    "\n",
    "    print (\"Accuracy = {:.3f}\".format(accuracy))\n",
    "    print (\"recall = {:.3f}\".format(recall))\n",
    "    print (\"precision = {:.3f}\".format(precision))\n",
    "    print (\"f1 = {:.3f}\".format(f1))\n",
    "\n",
    "    #print(metrics.classification_report(target, base_predictions))\n",
    "    #metrics.plot_confusion_matrix(baseline, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scorer    = metrics.make_scorer(metrics.accuracy_score)\n",
    "recall_scorer = metrics.make_scorer(metrics.recall_score, average='weighted')\n",
    "prec_scorer   = metrics.make_scorer(metrics.precision_score, average='weighted')\n",
    "f1_scorer     = metrics.make_scorer(metrics.f1_score, average='weighted')\n",
    "scoring = {'accuracy': acc_scorer, \n",
    "           'recall': recall_scorer, \n",
    "           'precision' : prec_scorer,\n",
    "           'f1': f1_scorer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_scores(model, train_data, train_labels, scoring, folds):\n",
    "    model_scores = ms.cross_validate (model,\n",
    "                                      train_data, \n",
    "                                      train_labels,\n",
    "                                      scoring=scoring,\n",
    "                                      cv=folds,\n",
    "                                      return_train_score=True)\n",
    "    np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "    print('\\n Evaluation results for {} folds:'.format(folds))\n",
    "    for (k,v) in model_scores .items():\n",
    "        print(('{}: {}').format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cross-validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(model, test_data, test_labels):\n",
    "    predictions = ms.cross_val_predict(model, test_data, test_labels)\n",
    "\n",
    "    cv_accuracy = metrics.accuracy_score(test_labels, predictions)\n",
    "    cv_recall = metrics.recall_score(test_labels, predictions, average='weighted')\n",
    "    cv_precision = metrics.precision_score(test_labels, predictions, average='weighted')\n",
    "    cv_f1 = metrics.f1_score(test_labels, predictions, average='weighted')\n",
    "    print('\\n Cross-validation predictions:')\n",
    "    print (\"accuracy = {:.3f}\".format(cv_accuracy))\n",
    "    print (\"recall = {:.3f}\".format(cv_recall))\n",
    "    print (\"precision = {:.3f}\".format(cv_precision))\n",
    "    print (\"f1 = {:.3f}\".format(cv_f1))\n",
    "\n",
    "    print(metrics.classification_report(test_labels, predictions))\n",
    "    metrics.confusion_matrix(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset and split dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "3    183\n",
      "5    182\n",
      "1    182\n",
      "6    181\n",
      "4    181\n",
      "9    180\n",
      "7    179\n",
      "0    178\n",
      "2    177\n",
      "8    174\n",
      "Name: target, dtype: int64\n",
      "Class distibution\n"
     ]
    }
   ],
   "source": [
    "digits, data, target = getDataset('digits')\n",
    "folds = 8\n",
    "\n",
    "# разбиваем выборки\n",
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(digits.data, digits.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.102\n",
      "recall = 0.102\n",
      "precision = 0.010\n",
      "f1 = 0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "getBaseline(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best F-score classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: \n",
      "f1 = 0.866\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 0.118  0.106  0.083  0.120  0.157  0.146  0.101  0.087]\n",
      "score_time: [ 0.024  0.015  0.013  0.027  0.045  0.042  0.012  0.012]\n",
      "test_accuracy: [ 0.883  0.864  0.839  0.836  0.872  0.850  0.888  0.855]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.883  0.864  0.839  0.836  0.872  0.850  0.888  0.855]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.894  0.868  0.853  0.847  0.871  0.858  0.897  0.855]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.884  0.864  0.839  0.836  0.870  0.852  0.888  0.854]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.781\n",
      "recall = 0.781\n",
      "precision = 0.786\n",
      "f1 = 0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        46\n",
      "           1       0.57      0.62      0.60        50\n",
      "           2       0.76      0.85      0.80        52\n",
      "           3       0.86      0.82      0.84        51\n",
      "           4       0.81      0.84      0.82        56\n",
      "           5       0.81      0.79      0.80        56\n",
      "           6       0.83      0.90      0.86        59\n",
      "           7       0.83      0.84      0.83        62\n",
      "           8       0.57      0.57      0.57        51\n",
      "           9       0.87      0.68      0.76        57\n",
      "\n",
      "    accuracy                           0.78       540\n",
      "   macro avg       0.78      0.78      0.78       540\n",
      "weighted avg       0.79      0.78      0.78       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=1, criterion='entropy');\n",
    "getDecisionTreeClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: \n",
      "f1 = 0.965\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 0.547  0.496  0.480  0.497  0.507  0.639  0.543  0.620]\n",
      "score_time: [ 0.011  0.015  0.010  0.013  0.011  0.021  0.010  0.018]\n",
      "test_accuracy: [ 0.963  0.969  0.969  0.943  0.962  0.882  0.941  0.980]\n",
      "train_accuracy: [ 0.994  0.996  0.996  0.995  0.995  0.996  0.997  0.994]\n",
      "test_recall: [ 0.963  0.969  0.969  0.943  0.962  0.882  0.941  0.980]\n",
      "train_recall: [ 0.994  0.996  0.996  0.995  0.995  0.996  0.997  0.994]\n",
      "test_precision: [ 0.966  0.970  0.971  0.946  0.963  0.900  0.943  0.981]\n",
      "train_precision: [ 0.994  0.996  0.996  0.996  0.995  0.996  0.997  0.994]\n",
      "test_f1: [ 0.963  0.969  0.969  0.943  0.961  0.886  0.941  0.980]\n",
      "train_f1: [ 0.994  0.996  0.996  0.995  0.995  0.996  0.997  0.994]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.930\n",
      "recall = 0.930\n",
      "precision = 0.934\n",
      "f1 = 0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        46\n",
      "           1       0.76      0.90      0.83        50\n",
      "           2       1.00      0.90      0.95        52\n",
      "           3       0.98      0.92      0.95        51\n",
      "           4       0.93      0.95      0.94        56\n",
      "           5       0.91      0.95      0.93        56\n",
      "           6       0.93      0.95      0.94        59\n",
      "           7       0.98      0.95      0.97        62\n",
      "           8       0.84      0.84      0.84        51\n",
      "           9       0.98      0.95      0.96        57\n",
      "\n",
      "    accuracy                           0.93       540\n",
      "   macro avg       0.93      0.93      0.93       540\n",
      "weighted avg       0.93      0.93      0.93       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(random_state = 1, max_iter = 1000)\n",
    "getLogisticRegression(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: \n",
      "f1 = 0.979\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 2.110  2.229  2.204  2.389  2.377  1.891  2.187  2.145]\n",
      "score_time: [ 0.393  0.246  0.293  0.307  0.483  0.234  0.306  0.383]\n",
      "test_accuracy: [ 0.981  0.994  0.988  0.969  0.962  0.948  0.961  0.993]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.981  0.994  0.988  0.969  0.962  0.948  0.961  0.993]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.983  0.994  0.988  0.970  0.962  0.951  0.962  0.994]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.981  0.994  0.988  0.969  0.961  0.948  0.960  0.993]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.948\n",
      "recall = 0.948\n",
      "precision = 0.949\n",
      "f1 = 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        46\n",
      "           1       0.91      0.96      0.93        50\n",
      "           2       0.96      0.96      0.96        52\n",
      "           3       0.92      0.94      0.93        51\n",
      "           4       0.95      0.98      0.96        56\n",
      "           5       0.98      0.98      0.98        56\n",
      "           6       0.98      0.98      0.98        59\n",
      "           7       0.95      0.98      0.97        62\n",
      "           8       0.88      0.84      0.86        51\n",
      "           9       0.98      0.86      0.92        57\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.95       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(random_state=1, n_estimators=150, criterion='entropy', max_leaf_nodes=200) \n",
    "getRandomForestClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes: \n",
      "f1 = 0.911\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 0.006  0.006  0.004  0.006  0.005  0.005  0.007  0.007]\n",
      "score_time: [ 0.015  0.017  0.015  0.022  0.025  0.013  0.017  0.009]\n",
      "test_accuracy: [ 0.926  0.914  0.907  0.874  0.910  0.843  0.921  0.908]\n",
      "train_accuracy: [ 0.908  0.906  0.910  0.917  0.910  0.915  0.910  0.910]\n",
      "test_recall: [ 0.926  0.914  0.907  0.874  0.910  0.843  0.921  0.908]\n",
      "train_recall: [ 0.908  0.906  0.910  0.917  0.910  0.915  0.910  0.910]\n",
      "test_precision: [ 0.934  0.924  0.913  0.882  0.914  0.865  0.930  0.911]\n",
      "train_precision: [ 0.914  0.911  0.915  0.922  0.916  0.919  0.916  0.916]\n",
      "test_f1: [ 0.928  0.915  0.908  0.875  0.910  0.843  0.922  0.907]\n",
      "train_f1: [ 0.909  0.907  0.911  0.918  0.911  0.916  0.911  0.911]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.883\n",
      "recall = 0.883\n",
      "precision = 0.888\n",
      "f1 = 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        46\n",
      "           1       0.81      0.68      0.74        50\n",
      "           2       0.89      0.90      0.90        52\n",
      "           3       0.90      0.86      0.88        51\n",
      "           4       0.89      0.96      0.92        56\n",
      "           5       1.00      0.82      0.90        56\n",
      "           6       0.98      0.98      0.98        59\n",
      "           7       0.95      0.97      0.96        62\n",
      "           8       0.75      0.86      0.80        51\n",
      "           9       0.73      0.81      0.77        57\n",
      "\n",
      "    accuracy                           0.88       540\n",
      "   macro avg       0.89      0.88      0.88       540\n",
      "weighted avg       0.89      0.88      0.88       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "getNaiveBayes(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: \n",
      "f1 = 0.974\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 1.957  2.238  1.881  2.094  2.311  1.859  1.967  1.968]\n",
      "score_time: [ 0.236  0.254  0.241  0.288  0.389  0.223  0.233  0.226]\n",
      "test_accuracy: [ 0.988  0.994  0.988  0.969  0.962  0.961  0.987  0.993]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.988  0.994  0.988  0.969  0.962  0.961  0.987  0.993]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.989  0.994  0.988  0.972  0.963  0.962  0.988  0.994]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.988  0.994  0.988  0.968  0.962  0.961  0.987  0.993]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.946\n",
      "recall = 0.946\n",
      "precision = 0.946\n",
      "f1 = 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.92      0.94      0.93        50\n",
      "           2       0.98      0.92      0.95        52\n",
      "           3       0.92      0.94      0.93        51\n",
      "           4       0.96      0.98      0.97        56\n",
      "           5       0.98      0.98      0.98        56\n",
      "           6       0.97      0.98      0.97        59\n",
      "           7       0.95      1.00      0.98        62\n",
      "           8       0.88      0.84      0.86        51\n",
      "           9       0.94      0.88      0.91        57\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.94       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.AdaBoostClassifier(random_state=1, base_estimator=ensemble.RandomForestClassifier(random_state=1, n_estimators=150, criterion='entropy'))\n",
    "getAdaBoostClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier: \n",
      "f1 = 0.942\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 1.703  1.551  1.506  1.381  1.712  1.628  1.305  1.211]\n",
      "score_time: [ 0.346  0.322  0.309  0.286  0.333  0.423  0.199  0.202]\n",
      "test_accuracy: [ 0.963  0.981  0.963  0.925  0.949  0.902  0.954  0.941]\n",
      "train_accuracy: [ 0.996  0.998  0.996  0.995  0.998  0.998  0.998  0.996]\n",
      "test_recall: [ 0.963  0.981  0.963  0.925  0.949  0.902  0.954  0.941]\n",
      "train_recall: [ 0.996  0.998  0.996  0.995  0.998  0.998  0.998  0.996]\n",
      "test_precision: [ 0.964  0.982  0.970  0.945  0.950  0.918  0.957  0.943]\n",
      "train_precision: [ 0.996  0.998  0.996  0.995  0.998  0.998  0.998  0.996]\n",
      "test_f1: [ 0.962  0.981  0.964  0.927  0.949  0.906  0.954  0.941]\n",
      "train_f1: [ 0.996  0.998  0.996  0.995  0.998  0.998  0.998  0.996]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.900\n",
      "recall = 0.900\n",
      "precision = 0.904\n",
      "f1 = 0.900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        46\n",
      "           1       0.75      0.88      0.81        50\n",
      "           2       0.90      0.90      0.90        52\n",
      "           3       0.98      0.86      0.92        51\n",
      "           4       0.90      0.93      0.91        56\n",
      "           5       0.90      0.95      0.92        56\n",
      "           6       0.95      0.95      0.95        59\n",
      "           7       0.92      0.90      0.91        62\n",
      "           8       0.89      0.78      0.83        51\n",
      "           9       0.96      0.86      0.91        57\n",
      "\n",
      "    accuracy                           0.90       540\n",
      "   macro avg       0.90      0.90      0.90       540\n",
      "weighted avg       0.90      0.90      0.90       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = ensemble.RandomForestClassifier(random_state=1, criterion='entropy', max_leaf_nodes=200) \n",
    "clf2 = linear_model.LogisticRegression(max_iter=1000);\n",
    "clf3 = ensemble.AdaBoostClassifier()\n",
    "\n",
    "model = ensemble.VotingClassifier(estimators=[('1', clf1), ('2', clf2), ('3', clf3)])\n",
    "\n",
    "getVotingClassifier(train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM: \n",
      "f1 = 0.991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        52\n",
      "           3       1.00      0.96      0.98        51\n",
      "           4       1.00      1.00      1.00        56\n",
      "           5       0.95      0.98      0.96        56\n",
      "           6       1.00      0.98      0.99        59\n",
      "           7       1.00      1.00      1.00        62\n",
      "           8       1.00      1.00      1.00        51\n",
      "           9       0.97      0.98      0.97        57\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n",
      "\n",
      " Evaluation results for 8 folds:\n",
      "fit_time: [ 1.969  2.686  2.924  2.282  2.202  2.003  2.273  2.005]\n",
      "score_time: [ 0.233  0.337  0.307  0.306  0.238  0.281  0.321  0.241]\n",
      "test_accuracy: [ 0.988  0.994  0.988  0.969  0.962  0.961  0.987  0.993]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.988  0.994  0.988  0.969  0.962  0.961  0.987  0.993]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.989  0.994  0.988  0.972  0.963  0.962  0.988  0.994]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.988  0.994  0.988  0.968  0.962  0.961  0.987  0.993]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.946\n",
      "recall = 0.946\n",
      "precision = 0.946\n",
      "f1 = 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        46\n",
      "           1       0.92      0.94      0.93        50\n",
      "           2       0.98      0.92      0.95        52\n",
      "           3       0.92      0.94      0.93        51\n",
      "           4       0.96      0.98      0.97        56\n",
      "           5       0.98      0.98      0.98        56\n",
      "           6       0.97      0.98      0.97        59\n",
      "           7       0.95      1.00      0.98        62\n",
      "           8       0.88      0.84      0.86        51\n",
      "           9       0.94      0.88      0.91        57\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.94       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params_svc = {'kernel': ['linear','poly','rbf'],\n",
    "                        'gamma': [1e-3, 1e-4, 'scale'],\n",
    "                        'C': [1, 10, 100, 1000]\n",
    "                       }\n",
    "\n",
    "getSVM(train_data, test_data, train_labels, test_labels, folds, hyper_params_svc)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast_canсer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset and split dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n",
      "Class distibution\n"
     ]
    }
   ],
   "source": [
    "breast_cancer, data, target = getDataset('breast_cancer')\n",
    "folds = 9\n",
    "# разбиваем выборки\n",
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(breast_cancer.data, breast_cancer.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.627\n",
      "recall = 0.627\n",
      "precision = 0.394\n",
      "f1 = 0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "getBaseline(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best F-score classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: \n",
      "f1 = 0.936\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.039  0.029  0.036  0.041  0.050  0.040  0.023  0.025  0.050]\n",
      "score_time: [ 0.011  0.014  0.017  0.013  0.040  0.011  0.010  0.008  0.022]\n",
      "test_accuracy: [ 0.889  0.889  0.933  1.000  0.909  0.886  0.909  0.930  0.930]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.889  0.889  0.933  1.000  0.909  0.886  0.909  0.930  0.930]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.891  0.888  0.935  1.000  0.915  0.898  0.920  0.932  0.930]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.889  0.888  0.934  1.000  0.910  0.888  0.906  0.931  0.930]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.930\n",
      "recall = 0.930\n",
      "precision = 0.932\n",
      "f1 = 0.930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        64\n",
      "           1       0.96      0.93      0.94       107\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.93      0.93       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=1, criterion='entropy')\n",
    "getDecisionTreeClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: \n",
      "f1 = 0.942\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.017  0.026  0.028  0.033  0.023  0.028  0.016  0.017  0.022]\n",
      "score_time: [ 0.013  0.012  0.020  0.026  0.015  0.028  0.010  0.008  0.009]\n",
      "test_accuracy: [ 0.911  0.933  1.000  0.978  0.864  0.977  0.955  0.977  1.000]\n",
      "train_accuracy: [ 0.972  0.972  0.958  0.960  0.966  0.958  0.960  0.955  0.958]\n",
      "test_recall: [ 0.911  0.933  1.000  0.978  0.864  0.977  0.955  0.977  1.000]\n",
      "train_recall: [ 0.972  0.972  0.958  0.960  0.966  0.958  0.960  0.955  0.958]\n",
      "test_precision: [ 0.916  0.933  1.000  0.979  0.864  0.978  0.958  0.978  1.000]\n",
      "train_precision: [ 0.972  0.972  0.957  0.960  0.966  0.958  0.960  0.955  0.958]\n",
      "test_f1: [ 0.912  0.933  1.000  0.978  0.864  0.977  0.954  0.977  1.000]\n",
      "train_f1: [ 0.972  0.972  0.957  0.960  0.966  0.958  0.960  0.955  0.958]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.924\n",
      "recall = 0.924\n",
      "precision = 0.924\n",
      "f1 = 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        64\n",
      "           1       0.93      0.95      0.94       107\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.92      0.91      0.92       171\n",
      "weighted avg       0.92      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(random_state = 1,max_iter = 2000)\n",
    "getLogisticRegression(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: \n",
      "f1 = 0.982\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.882  0.760  0.854  0.949  0.816  0.921  1.006  0.895  0.971]\n",
      "score_time: [ 0.170  0.163  0.196  0.185  0.162  0.214  0.229  0.237  0.203]\n",
      "test_accuracy: [ 0.956  0.933  1.000  0.978  0.932  0.909  0.955  1.000  0.977]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.956  0.933  1.000  0.978  0.932  0.909  0.955  1.000  0.977]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.956  0.933  1.000  0.979  0.932  0.927  0.958  1.000  0.978]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.956  0.933  1.000  0.978  0.931  0.911  0.954  1.000  0.977]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.965\n",
      "recall = 0.965\n",
      "precision = 0.965\n",
      "f1 = 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        64\n",
      "           1       0.96      0.98      0.97       107\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(random_state=1, n_estimators=150, criterion='entropy', max_leaf_nodes=100) \n",
    "getRandomForestClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes: \n",
      "f1 = 0.936\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.007  0.008  0.008  0.008  0.005  0.003  0.003  0.003  0.003]\n",
      "score_time: [ 0.017  0.038  0.048  0.024  0.022  0.012  0.009  0.010  0.009]\n",
      "test_accuracy: [ 0.867  0.911  0.978  0.956  0.864  0.977  0.932  0.977  0.977]\n",
      "train_accuracy: [ 0.943  0.941  0.935  0.943  0.952  0.935  0.944  0.938  0.938]\n",
      "test_recall: [ 0.867  0.911  0.978  0.956  0.864  0.977  0.932  0.977  0.977]\n",
      "train_recall: [ 0.943  0.941  0.935  0.943  0.952  0.935  0.944  0.938  0.938]\n",
      "test_precision: [ 0.874  0.916  0.979  0.959  0.864  0.979  0.938  0.978  0.978]\n",
      "train_precision: [ 0.943  0.941  0.935  0.944  0.953  0.935  0.944  0.939  0.938]\n",
      "test_f1: [ 0.862  0.912  0.978  0.955  0.864  0.977  0.930  0.977  0.977]\n",
      "train_f1: [ 0.943  0.940  0.934  0.943  0.952  0.935  0.943  0.937  0.938]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.936\n",
      "recall = 0.936\n",
      "precision = 0.936\n",
      "f1 = 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91        64\n",
      "           1       0.95      0.94      0.95       107\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.93      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "getNaiveBayes(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: \n",
      "f1 = 0.942\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.742  0.617  0.622  0.637  0.718  0.843  0.573  0.451  0.564]\n",
      "score_time: [ 0.154  0.145  0.143  0.195  0.183  0.145  0.085  0.095  0.090]\n",
      "test_accuracy: [ 0.911  0.933  1.000  0.978  0.886  0.977  0.955  0.977  1.000]\n",
      "train_accuracy: [ 0.975  0.972  0.960  0.963  0.966  0.955  0.963  0.961  0.958]\n",
      "test_recall: [ 0.911  0.933  1.000  0.978  0.886  0.977  0.955  0.977  1.000]\n",
      "train_recall: [ 0.975  0.972  0.960  0.963  0.966  0.955  0.963  0.961  0.958]\n",
      "test_precision: [ 0.916  0.933  1.000  0.979  0.889  0.978  0.958  0.978  1.000]\n",
      "train_precision: [ 0.974  0.972  0.960  0.963  0.966  0.955  0.963  0.961  0.958]\n",
      "test_f1: [ 0.912  0.933  1.000  0.978  0.887  0.977  0.954  0.977  1.000]\n",
      "train_f1: [ 0.974  0.972  0.960  0.963  0.966  0.955  0.963  0.961  0.958]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.947\n",
      "recall = 0.947\n",
      "precision = 0.947\n",
      "f1 = 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        64\n",
      "           1       0.95      0.96      0.96       107\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.AdaBoostClassifier(random_state=1, base_estimator=linear_model.LogisticRegression(random_state = 1))\n",
    "getAdaBoostClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier: \n",
      "f1 = 0.942\n",
      "\n",
      " Evaluation results for 9 folds:\n",
      "fit_time: [ 0.119  0.156  0.125  0.140  0.114  0.108  0.115  0.134  0.112]\n",
      "score_time: [ 0.031  0.040  0.047  0.051  0.041  0.033  0.037  0.055  0.032]\n",
      "test_accuracy: [ 0.911  0.933  1.000  1.000  0.909  0.977  0.932  1.000  0.977]\n",
      "train_accuracy: [ 0.997  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.911  0.933  1.000  1.000  0.909  0.977  0.932  1.000  0.977]\n",
      "train_recall: [ 0.997  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.911  0.933  1.000  1.000  0.915  0.979  0.938  1.000  0.978]\n",
      "train_precision: [ 0.997  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.911  0.933  1.000  1.000  0.910  0.977  0.930  1.000  0.977]\n",
      "train_f1: [ 0.997  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.959\n",
      "recall = 0.959\n",
      "precision = 0.959\n",
      "f1 = 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        64\n",
      "           1       0.96      0.97      0.97       107\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = ensemble.RandomForestClassifier(random_state=1, criterion='entropy', max_leaf_nodes=200) \n",
    "clf2 = linear_model.LogisticRegression(max_iter=1000);\n",
    "clf3 = tree.DecisionTreeClassifier(random_state=1, criterion='entropy')\n",
    "\n",
    "model = ensemble.VotingClassifier(estimators=[('1', clf1), ('2', clf2), ('3', clf3)])\n",
    "\n",
    "getVotingClassifier(train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVM: \n",
      "f1 = 0.907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.87      0.89        23\n",
      "           2       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.91      0.92      0.91        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.092  0.058  0.079  0.049  0.127  0.054  0.059  0.059  0.055  0.104\n",
      "  0.059  0.069  0.054  0.061]\n",
      "score_time: [ 0.043  0.044  0.051  0.035  0.071  0.031  0.049  0.041  0.038  0.060\n",
      "  0.036  0.051  0.034  0.030]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_accuracy: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_recall: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  0.906  1.000\n",
      "  0.906  1.000  0.906  1.000]\n",
      "train_precision: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.992  0.992  0.992  0.992\n",
      "  1.000  0.992  1.000  0.992]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  0.871  1.000\n",
      "  0.871  1.000  0.871  1.000]\n",
      "train_f1: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.981\n",
      "recall = 0.981\n",
      "precision = 0.982\n",
      "f1 = 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.99      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params_svc = {'kernel': ['linear','poly'],\n",
    "                        'gamma': ['scale'],\n",
    "                        'C': [1,100]\n",
    "                       }\n",
    "\n",
    "getSVM(train_data, test_data, train_labels, test_labels, folds, hyper_params_svc)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset and split dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: target, dtype: int64\n",
      "Class distibution\n"
     ]
    }
   ],
   "source": [
    "wine, data, target = getDataset('wine')\n",
    "folds = 14\n",
    "# разбиваем выборки\n",
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(wine.data, wine.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.399\n",
      "recall = 0.399\n",
      "precision = 0.159\n",
      "f1 = 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "getBaseline(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best F-score classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: \n",
      "f1 = 0.908\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.005  0.004  0.005  0.003  0.003  0.006  0.005  0.010  0.004  0.007\n",
      "  0.003  0.004  0.004  0.003]\n",
      "score_time: [ 0.010  0.014  0.010  0.008  0.013  0.009  0.011  0.012  0.009  0.013\n",
      "  0.009  0.008  0.009  0.009]\n",
      "test_accuracy: [ 0.909  1.000  1.000  0.900  0.889  1.000  0.875  1.000  0.875  1.000\n",
      "  0.750  0.875  0.875  1.000]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 0.909  1.000  1.000  0.900  0.889  1.000  0.875  1.000  0.875  1.000\n",
      "  0.750  0.875  0.875  1.000]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 0.927  1.000  1.000  0.920  0.926  1.000  0.906  1.000  0.906  1.000\n",
      "  0.781  0.917  0.906  1.000]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 0.905  1.000  1.000  0.898  0.892  1.000  0.863  1.000  0.871  1.000\n",
      "  0.738  0.875  0.871  1.000]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.907\n",
      "recall = 0.907\n",
      "precision = 0.917\n",
      "f1 = 0.909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.95      0.91      0.93        23\n",
      "           2       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.92      0.90      0.91        54\n",
      "weighted avg       0.92      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=1, criterion='entropy');\n",
    "getDecisionTreeClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: \n",
      "f1 = 0.926\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.015  0.012  0.015  0.007  0.006  0.012  0.008  0.013  0.006  0.007\n",
      "  0.007  0.007  0.007  0.008]\n",
      "score_time: [ 0.019  0.011  0.017  0.012  0.011  0.013  0.009  0.014  0.009  0.007\n",
      "  0.008  0.007  0.009  0.008]\n",
      "test_accuracy: [ 1.000  1.000  0.800  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  1.000  1.000  0.875  1.000]\n",
      "train_accuracy: [ 0.973  0.982  0.982  0.974  0.983  0.974  0.974  0.974  0.983  0.974\n",
      "  0.974  0.974  0.991  0.983]\n",
      "test_recall: [ 1.000  1.000  0.800  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  1.000  1.000  0.875  1.000]\n",
      "train_recall: [ 0.973  0.982  0.982  0.974  0.983  0.974  0.974  0.974  0.983  0.974\n",
      "  0.974  0.974  0.991  0.983]\n",
      "test_precision: [ 1.000  1.000  0.800  1.000  0.911  1.000  1.000  1.000  0.906  1.000\n",
      "  1.000  1.000  0.906  1.000]\n",
      "train_precision: [ 0.974  0.983  0.982  0.974  0.983  0.974  0.974  0.974  0.983  0.974\n",
      "  0.974  0.974  0.992  0.983]\n",
      "test_f1: [ 1.000  1.000  0.800  1.000  0.884  1.000  1.000  1.000  0.871  1.000\n",
      "  1.000  1.000  0.871  1.000]\n",
      "train_f1: [ 0.973  0.982  0.982  0.974  0.983  0.974  0.974  0.974  0.983  0.974\n",
      "  0.974  0.974  0.991  0.983]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.981\n",
      "recall = 0.981\n",
      "precision = 0.982\n",
      "f1 = 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.99      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(random_state = 1, max_iter = 1000)\n",
    "getLogisticRegression(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: \n",
      "f1 = 0.982\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 1.249  0.979  0.783  1.120  0.715  1.038  0.861  0.884  0.818  0.795\n",
      "  1.233  1.160  1.706  0.911]\n",
      "score_time: [ 0.342  0.316  0.425  0.278  0.336  0.379  0.353  0.320  0.260  0.356\n",
      "  0.547  0.325  0.408  0.233]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  1.000  1.000\n",
      "  0.906  1.000  0.906  1.000]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  1.000  1.000\n",
      "  0.871  1.000  0.871  1.000]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.944\n",
      "recall = 0.944\n",
      "precision = 0.952\n",
      "f1 = 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.87      0.93        23\n",
      "           2       0.86      1.00      0.92        18\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.96      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(random_state=1, n_estimators=200, criterion='entropy')\n",
    "getRandomForestClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes: \n",
      "f1 = 0.963\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.004  0.005  0.002  0.005  0.005  0.003  0.003  0.004  0.005  0.002\n",
      "  0.002  0.002  0.005  0.002]\n",
      "score_time: [ 0.015  0.030  0.014  0.019  0.020  0.012  0.029  0.016  0.020  0.013\n",
      "  0.015  0.013  0.011  0.012]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  0.750  1.000]\n",
      "train_accuracy: [ 0.991  0.973  0.974  0.991  0.983  0.974  0.983  0.983  0.991  0.991\n",
      "  0.991  0.974  1.000  0.983]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  0.750  1.000]\n",
      "train_recall: [ 0.991  0.973  0.974  0.991  0.983  0.974  0.983  0.983  0.991  0.991\n",
      "  0.991  0.974  1.000  0.983]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  1.000  1.000\n",
      "  0.906  1.000  0.850  1.000]\n",
      "train_precision: [ 0.991  0.974  0.974  0.991  0.983  0.974  0.983  0.983  0.992  0.992\n",
      "  0.992  0.974  1.000  0.983]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  1.000  1.000\n",
      "  0.871  1.000  0.719  1.000]\n",
      "train_f1: [ 0.991  0.973  0.974  0.991  0.983  0.974  0.983  0.983  0.991  0.991\n",
      "  0.991  0.974  1.000  0.983]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.963\n",
      "recall = 0.963\n",
      "precision = 0.964\n",
      "f1 = 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.96      0.96      0.96        23\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.97      0.96      0.96        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "getNaiveBayes(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: \n",
      "f1 = 0.982\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.672  0.558  0.613  0.590  0.548  1.024  0.979  0.589  0.725  0.690\n",
      "  1.022  1.010  0.990  0.691]\n",
      "score_time: [ 0.169  0.172  0.169  0.171  0.168  0.177  0.211  0.178  0.224  0.215\n",
      "  0.236  0.347  0.170  0.170]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  1.000  1.000]\n",
      "train_accuracy: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  1.000  1.000\n",
      "  0.875  1.000  1.000  1.000]\n",
      "train_recall: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  1.000  1.000\n",
      "  0.906  1.000  1.000  1.000]\n",
      "train_precision: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  1.000  1.000\n",
      "  0.871  1.000  1.000  1.000]\n",
      "train_f1: [ 1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000\n",
      "  1.000  1.000  1.000  1.000]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.963\n",
      "recall = 0.963\n",
      "precision = 0.967\n",
      "f1 = 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.91      0.95        23\n",
      "           2       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.97      0.97      0.97        54\n",
      "weighted avg       0.97      0.96      0.96        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.AdaBoostClassifier(random_state=1, base_estimator=ensemble.RandomForestClassifier(random_state=1, n_estimators=150, criterion='entropy'))\n",
    "getAdaBoostClassifier(model, train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier: \n",
      "f1 = 0.963\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.069  0.060  0.044  0.106  0.048  0.052  0.048  0.061  0.076  0.044\n",
      "  0.045  0.046  0.048  0.045]\n",
      "score_time: [ 0.057  0.034  0.037  0.059  0.030  0.038  0.046  0.032  0.030  0.031\n",
      "  0.029  0.031  0.031  0.033]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_accuracy: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_recall: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  0.906  1.000\n",
      "  0.906  1.000  0.906  1.000]\n",
      "train_precision: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.992  0.992  0.992  0.992\n",
      "  1.000  0.992  1.000  0.992]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  0.871  1.000\n",
      "  0.871  1.000  0.871  1.000]\n",
      "train_f1: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.981\n",
      "recall = 0.981\n",
      "precision = 0.982\n",
      "f1 = 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.99      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = ensemble.RandomForestClassifier(random_state=1) \n",
    "clf2 = linear_model.LogisticRegression(max_iter=1000);\n",
    "clf3 = naive_bayes.GaussianNB()\n",
    "\n",
    "model = ensemble.VotingClassifier(estimators=[('1', clf1), ('2', clf2), ('3', clf3)])\n",
    "\n",
    "getVotingClassifier(train_data, test_data, train_labels, test_labels)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\prog\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters:\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "SVM: \n",
      "f1 = 0.907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.87      0.89        23\n",
      "           2       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.91      0.92      0.91        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n",
      "\n",
      " Evaluation results for 14 folds:\n",
      "fit_time: [ 0.088  0.148  0.058  0.066  0.050  0.052  0.048  0.055  0.051  0.050\n",
      "  0.047  0.047  0.044  0.046]\n",
      "score_time: [ 0.048  0.055  0.036  0.030  0.031  0.033  0.032  0.030  0.029  0.031\n",
      "  0.031  0.029  0.031  0.027]\n",
      "test_accuracy: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_accuracy: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_recall: [ 1.000  1.000  1.000  1.000  0.889  1.000  1.000  1.000  0.875  1.000\n",
      "  0.875  1.000  0.875  1.000]\n",
      "train_recall: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "test_precision: [ 1.000  1.000  1.000  1.000  0.926  1.000  1.000  1.000  0.906  1.000\n",
      "  0.906  1.000  0.906  1.000]\n",
      "train_precision: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.992  0.992  0.992  0.992\n",
      "  1.000  0.992  1.000  0.992]\n",
      "test_f1: [ 1.000  1.000  1.000  1.000  0.892  1.000  1.000  1.000  0.871  1.000\n",
      "  0.871  1.000  0.871  1.000]\n",
      "train_f1: [ 0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991  0.991\n",
      "  1.000  0.991  1.000  0.991]\n",
      "\n",
      " Cross-validation predictions:\n",
      "accuracy = 0.981\n",
      "recall = 0.981\n",
      "precision = 0.982\n",
      "f1 = 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.99      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params_svc = {'kernel': ['linear','poly','rbf'],\n",
    "                        'gamma': [1e-3, 1e-4, 'scale'],\n",
    "                        'C': [1, 10, 100, 1000]\n",
    "                       }\n",
    "\n",
    "getSVM(train_data, test_data, train_labels, test_labels, folds, hyper_params_svc)\n",
    "cv_scores(model, train_data, train_labels, scoring, folds)\n",
    "cross(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits: RandomForestClassifier\n",
    "breast_cancer: RandomForestClassifier, SVM\n",
    "wine: LogisticRegression, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
